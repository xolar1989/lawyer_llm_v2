{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.6.0 requires tensorboard-data-server<0.7.0,>=0.6.0, which is not installed.\n",
      "mlflow 2.3.1 requires docker<7,>=4.0.0, but you have docker 7.1.0 which is incompatible.\n",
      "tensorboard 2.6.0 requires google-auth<2,>=1.6.3, but you have google-auth 2.6.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker>=2.199.0\" gradio transformers --upgrade --quiet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-07T12:46:32.582730Z",
     "end_time": "2024-09-07T12:47:56.600533Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\karol\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name superUser to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::767427092061:role/sagemaker_execution_role\n",
      "sagemaker session region: eu-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "region = 'eu-west-2'\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "sess = sagemaker.Session(boto_session=boto_session)\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(boto_session=boto_session, default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name=region)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-09T11:08:41.981925Z",
     "end_time": "2024-09-09T11:08:49.414262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "user_prompt = \"Znasz język polski? napisz coś o sienkiewiczu?\"\n",
    "\n",
    "prompt = f\"\"\"<s>[INST] <<SYS>>\n",
    "Jesteś pomocnym, pełnym szacunku i uczciwym asystentem. Zawsze odpowiadaj tak pomocnie, jak to możliwe, jednocześnie zachowując bezpieczeństwo. Twoje odpowiedzi nie powinny zawierać żadnych treści szkodliwych, nieetycznych, rasistowskich, seksistowskich, toksycznych, niebezpiecznych ani nielegalnych. Upewnij się, że twoje odpowiedzi są społecznie bezstronne i pozytywne.\n",
    "\n",
    "\n",
    "Jeśli pytanie nie ma sensu lub nie jest logicznie spójne, wyjaśnij dlaczego, zamiast udzielać niepoprawnej odpowiedzi. Jeśli nie znasz odpowiedzi na pytanie, nie podawaj fałszywych informacji.\n",
    "<</SYS>>\n",
    "{user_prompt} [/INST]\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-08T12:57:23.063465Z",
     "end_time": "2024-09-08T12:57:23.079459Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "'<s>[INST] <<SYS>>\\nJesteś pomocnym, pełnym szacunku i uczciwym asystentem. Zawsze odpowiadaj tak pomocnie, jak to możliwe, jednocześnie zachowując bezpieczeństwo. Twoje odpowiedzi nie powinny zawierać żadnych treści szkodliwych, nieetycznych, rasistowskich, seksistowskich, toksycznych, niebezpiecznych ani nielegalnych. Upewnij się, że twoje odpowiedzi są społecznie bezstronne i pozytywne.\\n\\n\\nJeśli pytanie nie ma sensu lub nie jest logicznie spójne, wyjaśnij dlaczego, zamiast udzielać niepoprawnej odpowiedzi. Jeśli nie znasz odpowiedzi na pytanie, nie podawaj fałszywych informacji.\\n<</SYS>>\\nZnasz język polski? napisz coś o sienkiewiczu? [/INST]\\n'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-08T12:57:30.769166Z",
     "end_time": "2024-09-08T12:57:30.781616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "kwargs = {\n",
    "    \"modelId\": \"meta.llama3-70b-instruct-v1:0\",\n",
    "    \"contentType\": \"application/json\",\n",
    "    \"accept\": \"*/*\",\n",
    "    \"body\": json.dumps(\n",
    "        {\n",
    "            \"prompt\": prompt,\n",
    "            \"max_gen_len\": 512,\n",
    "            \"temperature\": 0.5,\n",
    "            \"top_p\": 0.9,\n",
    "        }\n",
    "    )\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-08T12:57:46.538536Z",
     "end_time": "2024-09-08T12:57:46.541548Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(**kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-08T12:57:48.978551Z",
     "end_time": "2024-09-08T12:57:54.361974Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get('body').read())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-08T12:57:56.565046Z",
     "end_time": "2024-09-08T12:57:56.567849Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"generation\": \"Henryk Sienkiewicz to jeden z najwi\\u0119kszych pisarzy polskich, laureat Nagrody Nobla w dziedzinie literatury w 1905 roku. Urodzi\\u0142 si\\u0119 5 maja 1846 roku w Woli Okrzejskiej, a zmar\\u0142 15 listopada 1916 roku w Vevey w Szwajcarii.\\n\\nSienkiewicz jest autorem wielu znanych powie\\u015bci historycznych, takich jak \\\"Quo Vadis\\\", \\\"Krzy\\u017cacy\\\", \\\"Pan Wo\\u0142odyjowski\\\" i \\\"Na jaki\\u015b czas\\\". Jego tw\\u00f3rczo\\u015b\\u0107 by\\u0142a inspiracj\\u0105 dla wielu innych pisarzy i artyst\\u00f3w.\\n\\nW swoich utworach Sienkiewicz cz\\u0119sto podejmowa\\u0142 tematyk\\u0119 historyczn\\u0105, religijn\\u0105 i patriotyczn\\u0105. Jego styl pisarski charakteryzuje si\\u0119 bogactwem j\\u0119zyka, dynamizmem akcji i g\\u0142\\u0119bi\\u0105 psychologiczn\\u0105 postaci.\\n\\nWarto wspomnie\\u0107, \\u017ce Sienkiewicz by\\u0142 tak\\u017ce publicyst\\u0105 i redaktorem, a jego artyku\\u0142y i eseje by\\u0142y publikowane w r\\u00f3\\u017cnych czasopismach. Dzi\\u015b jest uwa\\u017cany za jednego z najwi\\u0119kszych pisarzy polskich wszech czas\\u00f3w.\",\n",
      "    \"prompt_token_count\": 235,\n",
      "    \"generation_token_count\": 306,\n",
      "    \"stop_reason\": \"stop\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response_body, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-08T12:57:58.318888Z",
     "end_time": "2024-09-08T12:57:58.323911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henryk Sienkiewicz to jeden z największych pisarzy polskich, laureat Nagrody Nobla w dziedzinie literatury w 1905 roku. Urodził się 5 maja 1846 roku w Woli Okrzejskiej, a zmarł 15 listopada 1916 roku w Vevey w Szwajcarii.\n",
      "\n",
      "Sienkiewicz jest autorem wielu znanych powieści historycznych, takich jak \"Quo Vadis\", \"Krzyżacy\", \"Pan Wołodyjowski\" i \"Na jakiś czas\". Jego twórczość była inspiracją dla wielu innych pisarzy i artystów.\n",
      "\n",
      "W swoich utworach Sienkiewicz często podejmował tematykę historyczną, religijną i patriotyczną. Jego styl pisarski charakteryzuje się bogactwem języka, dynamizmem akcji i głębią psychologiczną postaci.\n",
      "\n",
      "Warto wspomnieć, że Sienkiewicz był także publicystą i redaktorem, a jego artykuły i eseje były publikowane w różnych czasopismach. Dziś jest uważany za jednego z największych pisarzy polskich wszech czasów.\n"
     ]
    }
   ],
   "source": [
    "print(response_body['generation'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-08T12:59:24.122796Z",
     "end_time": "2024-09-08T12:59:24.128156Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '6deb8919-360c-412c-95e9-1b27b2c409b1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 08 Sep 2024 11:50:03 GMT', 'content-type': 'application/json', 'content-length': '89', 'connection': 'keep-alive', 'x-amzn-requestid': '6deb8919-360c-412c-95e9-1b27b2c409b1', 'x-amzn-bedrock-invocation-latency': '173', 'x-amzn-bedrock-output-token-count': '1', 'x-amzn-bedrock-input-token-count': '23'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0x000001C4C1DEBE80>}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-08T12:50:11.511981Z",
     "end_time": "2024-09-08T12:50:11.514997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The margin for 750.0 zł is 31.25 zł.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'type': 'function',\n 'function': {'name': 'oblicz_marze_detaliczna',\n  'description': 'Oblicza urzędową marżę detaliczną na podstawie ceny hurtowej leku, środka spożywczego specjalnego przeznaczenia żywieniowego albo wyrobu medycznego.\\n\\nArgumenty:\\ncena_hurtowa (float): Cena hurtowa w złotych.\\n\\nZwraca:\\nfloat: Obliczona marża detaliczna w złotych.\\n\\nUwagi:\\nFunkcja obsługuje różne przedziały cenowe zgodnie z dostarczoną tabelą marży detalicznej.',\n  'parameters': {'type': 'object',\n   'properties': {'cena_hurtowa': {}},\n   'required': ['cena_hurtowa']}}}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool, tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "import types\n",
    "\n",
    "\n",
    "def calculate_retail_margin(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    exec('''def oblicz_marze_detaliczna(cena_hurtowa):\n",
    "    \"\"\"\n",
    "    Oblicza urzędową marżę detaliczną na podstawie ceny hurtowej leku, środka spożywczego specjalnego przeznaczenia żywieniowego albo wyrobu medycznego.\n",
    "\n",
    "    Argumenty:\n",
    "    cena_hurtowa (float): Cena hurtowa w złotych.\n",
    "\n",
    "    Zwraca:\n",
    "    float: Obliczona marża detaliczna w złotych.\n",
    "\n",
    "    Uwagi:\n",
    "    Funkcja obsługuje różne przedziały cenowe zgodnie z dostarczoną tabelą marży detalicznej.\n",
    "    \"\"\"\n",
    "    if cena_hurtowa <= 5.00:\n",
    "        marza = 0.40 * cena_hurtowa\n",
    "    elif 5.01 <= cena_hurtowa <= 10.00:\n",
    "        marza = 2 + 0.30 * (cena_hurtowa - 5.00)\n",
    "    elif 10.01 <= cena_hurtowa <= 20.00:\n",
    "        marza = 3.50 + 0.20 * (cena_hurtowa - 10.00)\n",
    "    elif 20.01 <= cena_hurtowa <= 40.00:\n",
    "        marza = 5.50 + 0.15 * (cena_hurtowa - 20.00)\n",
    "    elif 40.01 <= cena_hurtowa <= 80.00:\n",
    "        marza = 8.50 + 0.10 * (cena_hurtowa - 40.00)\n",
    "    elif 80.01 <= cena_hurtowa <= 160.00:\n",
    "        marza = 12.50 + 0.05 * (cena_hurtowa - 80.00)\n",
    "    elif 160.01 <= cena_hurtowa <= 320.00:\n",
    "        marza = 16.50 + 0.025 * (cena_hurtowa - 160.00)\n",
    "    elif 320.01 <= cena_hurtowa <= 640.00:\n",
    "        marza = 20.50 + 0.025 * (cena_hurtowa - 320.00)\n",
    "    elif 640.01 <= cena_hurtowa <= 1280.00:\n",
    "        marza = 28.50 + 0.025 * (cena_hurtowa - 640.00)\n",
    "    else:\n",
    "        marza = 44.50 + 0.0125 * (cena_hurtowa - 1280.00)\n",
    "    return marza\n",
    "    ''')\n",
    "except SyntaxError as e:\n",
    "    print(f\"SyntaxError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "function_name = \"oblicz_marze_detaliczna\"\n",
    "calculate_margin = locals()[function_name]\n",
    "\n",
    "price = 750.00\n",
    "margin2 = calculate_margin(price)\n",
    "\n",
    "print(f\"The margin for {price} zł is {margin2} zł.\")\n",
    "\n",
    "calculate_retail_margin = tool(calculate_margin)\n",
    "\n",
    "# structured_tool = StructuredTool.from_function(func=calculate_retail_margin)\n",
    "\n",
    "# print(structured_tool.invoke({\"x\": price}))\n",
    "#\n",
    "# tools = []\n",
    "#\n",
    "# tools.append(calculate_retail_margin)\n",
    "#\n",
    "# print(calculate_retail_margin)\n",
    "# print(f\"The margin for {price} zł is {margin2} zł.\")\n",
    "l = convert_to_openai_tool(calculate_retail_margin)\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-11T13:11:23.699003Z",
     "end_time": "2024-09-11T13:11:24.962896Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-aws\n",
      "  Downloading langchain_aws-0.1.17-py3-none-any.whl (82 kB)\n",
      "     ---------------------------------------- 0.0/82.8 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 30.7/82.8 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ----- 71.7/82.8 kB 787.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 82.8/82.8 kB 772.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: boto3<1.35.0,>=1.34.131 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-aws) (1.34.145)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.33 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-aws) (0.2.34)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-aws) (1.24.3)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.145 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws) (1.34.145)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws) (0.10.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (0.1.92)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from botocore<1.35.0,>=1.34.145->boto3<1.35.0,>=1.34.131->langchain-aws) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from botocore<1.35.0,>=1.34.145->boto3<1.35.0,>=1.34.131->langchain-aws) (2.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.33->langchain-aws) (2.3)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.33->langchain-aws) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.33->langchain-aws) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.145->boto3<1.35.0,>=1.34.131->langchain-aws) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karol\\desktop\\python-projects\\pytorch-start\\env\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (2024.7.4)\n",
      "Installing collected packages: langchain-aws\n",
      "Successfully installed langchain-aws-0.1.17\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-aws"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-08T19:33:08.534259Z",
     "end_time": "2024-09-08T19:33:16.767250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "{'type': 'function',\n 'function': {'name': 'oblicz_marze_detaliczna',\n  'description': 'Funkcja oblicza urzędową marżę detaliczną na podstawie podanej ceny hurtowej leku, środka spożywczego specjalnego przeznaczenia żywieniowego lub wyrobu medycznego.\\n\\nArgumenty:\\ncena_hurtowa (float): Cena hurtowa produktu.\\n\\nZwraca:\\nfloat: Obliczona marża detaliczna.',\n  'parameters': {'type': 'object',\n   'properties': {'cena_hurtowa': {}},\n   'required': ['cena_hurtowa']}}}"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_community.llms import SagemakerEndpoint\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"meta.llama3-70b-instruct-v1:0\",\n",
    "    client=bedrock_runtime,\n",
    "    region_name=region,\n",
    "    model_kwargs=dict(temperature=0),\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "l = convert_to_openai_tool(calculate_retail_margin)\n",
    "\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-09T18:12:09.715266Z",
     "end_time": "2024-09-09T18:12:09.727413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('system', 'When you receive a tool call response, use the output to format an answer to the original user question.You are a helpful assistant with tool calling capabilities.'), ('human', ' Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\\n    Respond in the format {{\"name\": function name, \"parameters\": dictionary of argument name and its value}}.\\n    Do not use variables.\\n    {function}\\n    {function_2}\\n    Question: {input}')]\n",
      "content='{\"name\": \"oblicz_marze_detaliczna\", \"parameters\": {\"cena_hurtowa\": 750.0}}' additional_kwargs={'usage': {'prompt_tokens': 482, 'completion_tokens': 30, 'total_tokens': 512}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-70b-instruct-v1:0'} response_metadata={'usage': {'prompt_tokens': 482, 'completion_tokens': 30, 'total_tokens': 512}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-70b-instruct-v1:0'} id='run-3ad78ad4-7aff-483a-9067-e7c82d23f475-0' usage_metadata={'input_tokens': 482, 'output_tokens': 30, 'total_tokens': 512}\n",
      "content='Dla leku, którego cena hurtowa wynosi 750 zł, należy zastosować marżę detaliczną w wysokości 31.25 zł.' additional_kwargs={'usage': {'prompt_tokens': 415, 'completion_tokens': 39, 'total_tokens': 454}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-70b-instruct-v1:0'} response_metadata={'usage': {'prompt_tokens': 415, 'completion_tokens': 39, 'total_tokens': 454}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-70b-instruct-v1:0'} id='run-e846b322-cc7a-4b02-9d2c-24537d7d5a6d-0' usage_metadata={'input_tokens': 415, 'output_tokens': 39, 'total_tokens': 454}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "\n",
    "k = '''{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_conditions\",\n",
    "        \"description\": \"Get the current weather conditions for a specific location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"Celsius\", \"Fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the user's location.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "    }\n",
    "}'''\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        '''When you receive a tool call response, use the output to format an answer to the original user question.You are a helpful assistant with tool calling capabilities.'''\n",
    "    ),\n",
    "    (\"human\", ''' Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
    "    Respond in the format {{\"name\": function name, \"parameters\": dictionary of argument name and its value}}.\n",
    "    Do not use variables.\n",
    "    {function}\n",
    "    {function_2}\n",
    "    Question: {input}'''\n",
    "\n",
    "     ),\n",
    "]\n",
    "\n",
    "print(messages)\n",
    "\n",
    "prompt_bedrock = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "bedrock_chain = prompt_bedrock | llm\n",
    "\n",
    "ai_msg = bedrock_chain.invoke(\n",
    "    {\"input\": \"Jaką marżę detaliczną należy zastosować dla leku, którego cena hurtowa wynosi 750 zł?\",\n",
    "     \"function\": str(l),\n",
    "     \"function_2\": k\n",
    "     }\n",
    ")\n",
    "\n",
    "messages_for_return_function = [\n",
    "    (\n",
    "        \"system\",\n",
    "        f'''\n",
    "        You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal use question.'''\n",
    "    ),\n",
    "    (\"human\", ''' Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
    "    Respond in the format {{\"name\": function name, \"parameters\": dictionary of argument name and its value}}.\n",
    "    Do not use variables.\n",
    "    {function}\n",
    "    Question: {input}'''\n",
    "     ),\n",
    "    (\"ai\", \"{ai_content} Now here is the result of called function <|start_header_id|>ipython<|end_header_id|> {{'output':' \"+str(margin2) +\"'}}  Now using full sentences using polish language answer the question. Pay attention to the correctness of the answer like units \"),\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "print(ai_msg)\n",
    "\n",
    "prompt_becdrock_return_function = ChatPromptTemplate.from_messages(messages_for_return_function)\n",
    "\n",
    "bedrock_chain_return_function = prompt_becdrock_return_function | llm\n",
    "\n",
    "ai_msg_return_function = bedrock_chain_return_function.invoke(\n",
    "    {\"input\": \"Jaką marżę detaliczną należy zastosować dla leku, którego cena hurtowa wynosi 750 zł?\",\n",
    "\n",
    "     \"function\": str(l),\n",
    "    \"ai_content\": ai_msg.content\n",
    "     }\n",
    ")\n",
    "\n",
    "print(ai_msg_return_function)\n",
    "\n",
    "# ai_msg_2 = bedrock_chain.invoke(\n",
    "#     {\"input\": \"Jaka jest pogoda w Warszawie?\",\n",
    "#      \"function\": str(l),\n",
    "#      \"function_2\": k\n",
    "#      }\n",
    "# )\n",
    "#\n",
    "# print(ai_msg_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-09T19:52:48.918251Z",
     "end_time": "2024-09-09T19:52:50.318384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 'Jaką marżę detaliczną należy zastosować dla leku, którego cena hurtowa wynosi 750 zł?',\n 'output': 'W Polsce marża detaliczna dla leków jest uregulowana przepisami prawa. Zgodnie z art. 15 ust. 2 ustawy z dnia 6 września 2001 r. - Prawo farmaceutyczne (Dz. U. z 2021 r. poz. 1977), marża detaliczna dla leków nie może przekraczać 50% ceny hurtowej leku.\\n\\nW przypadku leku, którego cena hurtowa wynosi 750 zł, marża detaliczna nie może być wyższa niż 375 zł (50% z 750 zł).\\n\\nCena detaliczna leku powinna więc wynosić:\\n\\n750 zł (cena hurtowa) + 375 zł (marża detaliczna) = 1125 zł\\n\\nWarto zauważyć, że powyższa kalkulacja jest uproszczona i nie uwzględnia innych kosztów, które mogą być doliczone do ceny leku, takich jak podatek VAT czy koszty logistyki.'}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain_community.llms import AmazonAPIGateway\n",
    "from langchain_community.agents.openai_assistant import OpenAIAssistantV2Runnable\n",
    "\n",
    "tools = [calculate_retail_margin]\n",
    "# agent = OpenAIAssistantV2Runnable.create_assistant(\n",
    "#     name=\"langchain assistant\",\n",
    "#     instructions=\"Jesteś doradcą prawnym który ma odpowiadać na zadane pytania używając otrzymane narzędzia funkcje\",\n",
    "#     tools=tools,\n",
    "#     model=\"gpt-4o\",\n",
    "# )\n",
    "modelLlama = llm\n",
    "prompt4o = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"Jesteś doradcą prawnym który ma odpowiadać na zadane pytania używając otrzymane narzędzia funkcje, zwróc uwagę na poprawność odpowiedzi i zastosowanie polskich znaków diakrytycznych\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        # # Placeholders fill up a **list** of messages\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "agent = create_tool_calling_agent(modelLlama, tools, prompt4o)\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "kk = agent_executor.invoke(\n",
    "    {\"input\": \"Jaką marżę detaliczną należy zastosować dla leku, którego cena hurtowa wynosi 750 zł?\"})\n",
    "# kk = agent_executor.invoke({\"input\": \"ile jest 2+2?\"})\n",
    "\n",
    "kk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-09T12:19:57.009533Z",
     "end_time": "2024-09-09T12:20:37.227995Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
